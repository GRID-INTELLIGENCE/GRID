# Guide: How System Handles Unsatisfying First Results

## Quick Answer

**The system does NOT have explicit instructions saying "if first result doesn't satisfy, do X."**

Instead, it's designed to handle this automatically through:

1. **Threshold Filtering** - Results below `min_score` are excluded BEFORE processing
2. **Score-Order Processing** - Instructions say "process results IN ORDER OF SCORE" (not just first)
3. **Cross-Checking** - When multiple matches exist, automatically cross-check for conflicts
4. **Explicit Fallback** - If no good matches exist, returns explicit "No results found" message

## How It Actually Works

### 1. Threshold Filtering (Primary Defense)

**Code Location**: `datakit/tool/semantic_grep.py`, lines 193-195

```python
for i in idxs.tolist():
    score = float(scored[i])
    if score < min_score:  # ← Filter happens HERE
        continue  # Skip this result entirely
```

**What happens**:
- All results below `min_score` (default 0.15) are filtered out BEFORE any processing
- If first result has score < threshold, it's skipped entirely
- Processing starts with the highest-scoring result that meets the threshold

**Example**:
```
Query: "database connection"
Results: [score: 0.12, 0.45, 0.32, 0.25, 0.18]
min_score: 0.15

Filtered results: [0.45, 0.32, 0.25, 0.18]  ← First result (0.12) skipped
Effective "first" result: 0.45 (originally #2)
```

### 2. Score-Order Processing (Core Instruction)

**Code Location**: `datakit/tool/semantic_grep.py`, lines 136-137

```python
instructions.append(
    "Read the matched line ranges in order of score; "
    "extract definitions, invariants, and constraints."
)
```

**Key phrase**: "**IN ORDER OF SCORE**" - not "use first result"

This means:
- Process ALL top matches, sorted by score (highest first)
- Don't stop at the first result
- Evaluate multiple candidates before making a decision

### 3. Cross-Checking (Automatic Conflict Resolution)

**Code Location**: `datakit/tool/semantic_grep.py`, lines 150-153

```python
if top_chunks:  # ← Only if matches exist
    instructions.append(
        "Cross-check similar matches for conflicts; "
        "prefer the most recent or most authoritative reference."
    )
```

**What this means**:
- When multiple matches exist, automatically generate cross-checking instruction
- Compare matches for consistency
- Resolve conflicts by preferring:
  1. Most recent source
  2. Most authoritative source (canonical docs, official specs)

**Example**:
```
Query: "API endpoint configuration"
Matches found: 5
Instructions include:
  - "Cross-check similar matches for conflicts"
  - "Prefer the most recent or most authoritative reference"

Action: Compare all 5 matches, resolve conflicts, prefer canonical docs
```

### 4. RAG Engine Fallback (Explicit Acknowledgment)

**Code Location**: `tools/rag/rag_engine.py`, lines 188-189

```python
if not results["documents"]:
    return {
        "answer": "No relevant documents found in the knowledge base.",
        "sources": [],
        "context": ""
    }
```

**What this means**:
- If no documents found, return explicit "No relevant documents found"
- Don't hallucinate or use poor matches
- Acknowledge uncertainty explicitly

## Practical Examples

### Example 1: First Result Below Threshold

```python
# Query
query = "obscure feature xyz"
min_score = 0.15

# Results (before filtering)
scores = [0.08, 0.25, 0.18, 0.32, 0.12]

# After threshold filtering
filtered = [0.25, 0.18, 0.32]  # 0.08 and 0.12 below threshold

# Processing
- First result (0.08) is SKIPPED automatically
- Processing starts with 0.25 (highest above threshold)
- All remaining results processed in score order
```

### Example 2: Multiple Results Above Threshold

```python
# Query
query = "implement database connection"
min_score = 0.15

# Results (after filtering)
scores = [0.85, 0.72, 0.65, 0.58, 0.42]

# Instructions generated
1. "Identify relevant files and sections from top matches"
2. "Read matched line ranges IN ORDER OF SCORE"  ← Process all 5
3. "Derive an interface from the matches"
4. "Cross-check similar matches for conflicts"  ← Added automatically
5. "Summarize findings into structured output"

# Processing
- Evaluate result 1 (0.85) - highest quality
- Evaluate result 2 (0.72) - cross-check for conflicts
- Evaluate result 3 (0.65) - verify consistency
- Continue through all 5 results
- Prefer most recent/authoritative if conflicts found
```

### Example 3: No Results Above Threshold

```python
# Query
query = "completely unrelated topic"
min_score = 0.15

# Results (before filtering)
scores = [0.05, 0.03, 0.02, 0.01]

# After threshold filtering
filtered = []  # All below threshold

# RAG Engine Response
{
    "answer": "No relevant documents found in the knowledge base.",
    "sources": [],
    "context": ""
}

# Semantic Grep Response
{
    "matches": [],  # Empty list
    "logical_instructions": [...]  # Instructions still generated
}
```

## Instructions Generated by Query Type

### Bug-Fixing Queries

**Keywords**: "bug", "error", "fix", "issue", "broken"

**Additional Instructions**:
- "Locate error messages / stack traces in matched sections and trace callers upward"
- "Form a minimal reproduction path using the matched references, then apply targeted fix"

### Implementation Queries

**Keywords**: "implement", "create", "add", "build", "tool"

**Additional Instructions**:
- "Derive an interface from the matches (inputs/outputs), then sketch a minimal implementation plan"

### General Queries

**Default Instructions**:
- "Identify the relevant files and sections from the top matches"
- "Read the matched line ranges in order of score; extract definitions, invariants, and constraints"
- "Summarize findings into a structured output (problem, evidence, steps, expected result)"

## When First Result Doesn't Satisfy: What To Do

### As a User/Developer

1. **Check if result is below threshold**
   ```python
   if first_result['score'] < min_score:
       # Result was already filtered out
       # Check remaining results
   ```

2. **Lower threshold if needed**
   ```python
   # Original query
   result = run_semantic_grep(..., min_score=0.15)

   # If first result unsatisfactory, try lower threshold
   result = run_semantic_grep(..., min_score=0.10)
   ```

3. **Review all top_k results**
   ```python
   # Don't just look at first result
   for match in results['matches']:
       print(f"Score: {match['score']}, File: {match['file']}")
   ```

4. **Cross-check multiple matches**
   - Compare definitions across matches
   - Check for conflicts or inconsistencies
   - Prefer canonical/authoritative sources

5. **Acknowledge uncertainty**
   - If no good matches exist, explicitly say so
   - Don't hallucinate or force a pattern
   - Use "Mist" state if pattern detected but structure unknowable

### As the System (Automatic Behavior)

The system automatically:
- Filters by threshold (no configuration needed)
- Processes in score order (built-in)
- Cross-checks when multiple matches exist (automatic)
- Returns explicit "no results" when appropriate (automatic)
- Adapts instructions based on query type (automatic)

## Key Takeaways

1. **No explicit "if first doesn't satisfy" instruction** - The design prevents this through threshold filtering and score-order processing

2. **Threshold filtering is automatic** - Results below `min_score` are excluded before processing

3. **Multiple results are always considered** - Instructions explicitly say "in order of score", not "use first result"

4. **Cross-checking is automatic** - When multiple matches exist, conflict resolution instructions are automatically generated

5. **Explicit fallback** - Both RAG and Semantic Grep explicitly acknowledge when no good matches exist

6. **Adaptive instructions** - Instructions vary based on query type and number of matches

## Running the Demo

See the demonstration script:
```bash
python tools/demo_unsatisfying_results.py
```

This shows:
- Score threshold filtering in action
- Processing order behavior
- Cross-checking mechanism
- RAG engine fallback
- Instruction variation by query type
- Practical impact of threshold selection

## Related Files

- `datakit/tool/semantic_grep.py` - Core search and instruction generation
- `tools/rag/rag_engine.py` - RAG query engine with fallback
- `tools/rag/store.py` - Vector store with threshold filtering
- `tools/demo_unsatisfying_results.py` - Practical demonstration
- `tools/demo_result_flow.md` - Visual flow diagram
