```wellness_studio/AI SAFETY - OPENAI/REPORT_TEMPLATE.md#L1-200
# OpenAI AI Safety Research Report Template

## 1) Report Metadata
- Report Title:
- Version:
- Author(s):
- Date:
- Scope Period:
- Primary Audience:
- Repository/Folder:

## 2) Executive Summary
- Key safety themes observed:
- Most significant risks:
- Primary mitigations identified:
- User-centric implications:
- Recommended actions:

## 3) Scope & Inclusion Criteria
- Included sources (Research Index + Safety pages + System Cards):
- Excluded sources:
- Relevance rules (why each item is included):
- Safety focus definition:

## 4) Source Inventory (Structured)
> Use the schema below to populate a spreadsheet or database.

**Schema Fields**
- Source Title
- URL
- Date
- Category (Research / Publication / Safety Hub / System Card)
- Safety Theme(s)
- Methods / Evaluation Type
- Key Findings
- User Guidance Implications
- User Rights Implications
- Remediation Steps
- Relevance Score (1-5)
- Notes

## 5) Safety Taxonomy (User-Centric)
- 5.1 Safe Use & Boundaries
- 5.2 Evaluation & Compliance
- 5.3 Deception & Misalignment
- 5.4 Instruction Hierarchy & Policy Adherence
- 5.5 Accuracy & Hallucinations
- 5.6 Transparency & Accountability
- 5.7 Privacy & Personal Data
- 5.8 System-Level Safeguards

## 6) Scenario-Based Analysis
> For each scenario, document expected model behavior, user rights, and remediation steps.

### Scenario Template
- Scenario Name:
- Description:
- Safety Theme:
- Risk Type:
- Expected Model Behavior:
- User Rights Affected:
- Evidence Source(s):
- Remediation Steps:
- Residual Risk:

## 7) User Rights Section
- Right to safety constraints and refusal in unsafe contexts
- Right to transparency about limitations and uncertainty
- Right to guidance on acceptable use
- Right to remediation pathways when safety issues occur
- Right to privacy and minimal data exposure

## 8) Remediation Playbook (Step-by-Step)
1. Identify issue category
2. Check instruction hierarchy conflicts
3. Validate outputs (cross-check with trusted sources)
4. Re-prompt using safe framing
5. Document and escalate if persistent
6. Apply mitigation and retest

## 9) Evidence Mapping
- Map each user-facing recommendation to source(s)
- Note any conflicts or gaps between sources

## 10) Findings & Analysis
- What’s confirmed by multiple sources:
- What’s uncertain or under-evaluated:
- Trend analysis (over time, if applicable):

## 11) Gaps & Open Questions
- Missing evaluations:
- Underexplored risks:
- Recommendations for future research:

## 12) Appendices
- A) Source List
- B) Glossary of Safety Terms
- C) Evaluation Methods Summary
- D) Change Log
