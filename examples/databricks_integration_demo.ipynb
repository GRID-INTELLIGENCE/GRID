{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41b1eed3",
   "metadata": {},
   "source": [
    "# Databricks SDK Integration with GRID\n",
    "\n",
    "This notebook demonstrates how to use the Databricks SDK with the GRID framework for job orchestration, cluster management, and notebook operations.\n",
    "\n",
    "**Prerequisites:**\n",
    "- Set `DATABRICKS_HOST` environment variable with your workspace URL\n",
    "- Set `databricks` or `DATABRICKS_TOKEN` environment variable with your API key\n",
    "- `databricks-sdk>=0.40.0` installed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efc4199",
   "metadata": {},
   "source": [
    "## 1. Install and Import Databricks SDK\n",
    "\n",
    "First, let's ensure the databricks-sdk package is installed and import the necessary modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0a670e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Environment configured\n",
      "   Python path includes: e:\\grid\n",
      "   DATABRICKS_HOST: https://dbc-9747ff30-23c5.cloud.databricks.com\n",
      "   databricks token: SET\n",
      "‚úÖ databricks-sdk is installed and importable\n"
     ]
    }
   ],
   "source": [
    "# Setup: Add workspace to path and configure environment\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Add workspace root to path\n",
    "workspace_root = \"e:\\\\grid\"\n",
    "if workspace_root not in sys.path:\n",
    "    sys.path.insert(0, workspace_root)\n",
    "\n",
    "# Set Databricks host - use the full URL without /browse/folders path\n",
    "DATABRICKS_HOST = \"https://dbc-9747ff30-23c5.cloud.databricks.com\"\n",
    "os.environ[\"DATABRICKS_HOST\"] = DATABRICKS_HOST\n",
    "\n",
    "print(\"‚úÖ Environment configured\")\n",
    "print(f\"   Python path includes: {workspace_root}\")\n",
    "print(f\"   DATABRICKS_HOST: {os.getenv('DATABRICKS_HOST')}\")\n",
    "print(f\"   databricks token: {'SET' if os.getenv('databricks') else 'NOT SET'}\")\n",
    "\n",
    "# Verify databricks-sdk is installed\n",
    "try:\n",
    "    import databricks.sdk\n",
    "    print(\"‚úÖ databricks-sdk is installed and importable\")\n",
    "except ImportError:\n",
    "    print(\"‚ùå databricks-sdk not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174de138",
   "metadata": {},
   "source": [
    "## 2. Initialize Databricks Client\n",
    "\n",
    "Create a DatabricksClient instance using environment variables. The client supports multiple authentication methods:\n",
    "- `DATABRICKS_HOST` (required) - Your Databricks workspace URL\n",
    "- `DATABRICKS_TOKEN` or `databricks` (required) - Your API token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0ca7660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All GRID Databricks modules imported successfully!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from src.integration.databricks import (\n",
    "        DatabricksClient,\n",
    "        DatabricksClustersManager,\n",
    "        DatabricksJobsManager,\n",
    "        DatabricksNotebooksManager,\n",
    "    )\n",
    "    print(\"‚úÖ All GRID Databricks modules imported successfully!\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Import error: {e}\")\n",
    "    print(\"\\nTrying alternative import...\")\n",
    "    # Try direct module import\n",
    "    from src.integration.databricks.client import DatabricksClient\n",
    "    from src.integration.databricks.jobs import DatabricksJobsManager\n",
    "    print(\"‚úÖ Imports successful via direct module paths\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8a7176",
   "metadata": {},
   "source": [
    "## 3. Cluster Management\n",
    "\n",
    "Let's explore cluster operations available through the client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63d20cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîå Connecting to Databricks...\n",
      "‚úÖ Successfully connected!\n",
      "\n",
      "üìä Listing clusters in your workspace...\n",
      "‚úÖ Connected successfully! No clusters currently running.\n",
      "   (You can create clusters in the Databricks UI or via API)\n"
     ]
    }
   ],
   "source": [
    "# Initialize client (reads DATABRICKS_HOST and 'databricks' env vars)\n",
    "print(\"üîå Connecting to Databricks...\")\n",
    "try:\n",
    "    client = DatabricksClient()\n",
    "    print(\"‚úÖ Successfully connected!\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Connection failed: {e}\")\n",
    "    print(\"   Make sure DATABRICKS_HOST and 'databricks' env vars are set\")\n",
    "    raise\n",
    "\n",
    "# Now test a simple operation\n",
    "print(\"\\nüìä Listing clusters in your workspace...\")\n",
    "try:\n",
    "    clusters = client.list_clusters()\n",
    "\n",
    "    if clusters:\n",
    "        print(f\"‚úÖ Found {len(clusters)} cluster(s):\")\n",
    "        for cluster in clusters:\n",
    "            print(f\"  üìç {cluster.get('cluster_name', 'Unknown')} (ID: {cluster.get('cluster_id')})\")\n",
    "    else:\n",
    "        print(\"‚úÖ Connected successfully! No clusters currently running.\")\n",
    "        print(\"   (You can create clusters in the Databricks UI or via API)\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938f9b89",
   "metadata": {},
   "source": [
    "## 4. Job Management\n",
    "\n",
    "Create and run jobs using DatabricksJobsManager.\n",
    "\n",
    "**Note:** This example shows the structure. Replace with your actual notebook paths and job names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61e063f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Existing Jobs in Workspace:\n",
      "\n",
      "  No jobs found\n",
      "\n",
      "üìù Example: Creating a Notebook Job\n",
      "\n",
      "\n",
      "    # To create a job, use:\n",
      "    job_id = jobs_manager.create_notebook_job(\n",
      "        job_name=\"my-processing-job\",\n",
      "        notebook_path=\"/Repos/user/project/process_data.ipynb\",\n",
      "        cluster_id=\"cluster-123\",  # Use cluster from step 3\n",
      "        base_parameters={\"input_path\": \"/data/input\"}\n",
      "    )\n",
      "    print(f\"Created job {job_id}\")\n",
      "\n",
      "    # Then run it:\n",
      "    run_id = jobs_manager.run_job(job_id)\n",
      "    print(f\"Started run {run_id}\")\n",
      "    \n",
      "‚úÖ Jobs manager initialized successfully!\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "try:\n",
    "    jobs_manager = DatabricksJobsManager(client)\n",
    "\n",
    "    # List existing jobs\n",
    "    print(\"üìã Existing Jobs in Workspace:\\n\")\n",
    "    jobs = jobs_manager.list_jobs()\n",
    "\n",
    "    if not jobs:\n",
    "        print(\"  No jobs found\")\n",
    "    else:\n",
    "        for i, job in enumerate(jobs[:5], 1):  # Show first 5\n",
    "            print(f\"  {i}. {job['settings']}\")\n",
    "            print(f\"     Job ID: {job['job_id']}\")\n",
    "            print()\n",
    "\n",
    "    # Example: Create a notebook job (commented out - customize for your use)\n",
    "    print(\"\\nüìù Example: Creating a Notebook Job\\n\")\n",
    "    print(\"\"\"\n",
    "    # To create a job, use:\n",
    "    job_id = jobs_manager.create_notebook_job(\n",
    "        job_name=\"my-processing-job\",\n",
    "        notebook_path=\"/Repos/user/project/process_data.ipynb\",\n",
    "        cluster_id=\"cluster-123\",  # Use cluster from step 3\n",
    "        base_parameters={\"input_path\": \"/data/input\"}\n",
    "    )\n",
    "    print(f\"Created job {job_id}\")\n",
    "\n",
    "    # Then run it:\n",
    "    run_id = jobs_manager.run_job(job_id)\n",
    "    print(f\"Started run {run_id}\")\n",
    "    \"\"\")\n",
    "\n",
    "    print(\"‚úÖ Jobs manager initialized successfully!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error with jobs manager: {e}\")\n",
    "    jobs_manager = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2b201b",
   "metadata": {},
   "source": [
    "## 5. Notebook Operations\n",
    "\n",
    "Manage notebooks in the Databricks workspace."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
